杉树科技
1、spark通信机制了解吗？
2、hive on spark了解过吗？
3、优化说了提高并行度之后，给256g内存，32C写下提交参数。
4、udf和udaf写过吗？有什么区别？有一个场景，用udf实现一个字段自增怎么弄？
5、利用流的思想分析历史数据，怎么实现？
6、kafka数据什么时候落地磁盘？kafka中offset的编号规则是什么？ 大概是这样  topic、partition、segment中的offset编码规则
7、storm的容错机制
8、怎么优化shffle
9、rdd怎么转dataFrame
10、关于reduceByKey  底层？ 忘了具体什么问题了
11、OOM的原因？如何分析定位并解决的？
12、a、b两个文件 存的都是url  内存有限  怎么找到a、b相同的url
13、懒加载  好像大数据方向的  我扯到mybatis去了
14、问了我spark、jdk、scala的版本，说太低了
15、redis雪崩现象  zookeeper脑裂
问了还有挺多，忘了
15、并发性？
16、多线程有几种创建方式？
17、代码怎么确定二叉树的高度？
18、怎么确定一个链表是一个环形链表？我说的是两个指针，一个固定另一个一个一个遍历，他又问了如果两个指针都必须要动呢?
19、说到关于有向无环图之后 问了 图的存储方式
20、栈、队列的区别 好像是怎么使用两个堆栈实现队列
21、你项目都负责了哪些模块？你感觉你做的比较出色的说一下？
22、单例 工厂模式


脉脉
1、为什么选择kafka  kafka为什么快
2、spark提交一个任务的流程
3、快排的思想？二分法的时间复杂度？
4、spark和storm的区别？选型时怎么考虑的
5、比如一个hsql语句 select ... count(*) from ... left join .. on .. 底层是怎么执行的？
6、persist和checkpoint的区别
7、spark和mapreduce的对比
8、u_id1  u_id2 分别对应的是两个用户  是好友关系  找他们的二级好友 写伪代码   mapreduce spark都可以
   如果是实时的情况，动态添加添加好友或删除好友的记录，二级好友怎么实时修改
9、一个50亿行的文件，存的都是数字，内存有限  怎么找到中位数
10、hbase预分区的知识   我说了我们是按照业务的检测单号倒过来当的rowkey   他说这样会有什么问题
11、hashmap hashtable concurrenthashmap 区别
12、sqoop怎么增量导入数据
13、数据增量

京东金融
画下项目的架构图介绍下项目？介绍下你做的哪些方面？
介绍下kafka  topic容错机制  高水位机制
zookeeper原子广播协议
hbase优化  rowkey设计  
知道哪些过滤器  底层运行机制什么 比如filterFilter
hive的优化  数据倾斜 
内部表外部表的区别  hdfs数据导入到hive的语法 
写过udf的场景
spark提交任务的流程
cache和persist的区别   reduceBykey和groupByKey
随便写一个算法
工厂模式
场景题：出租车上的GPS每分钟生成三个点的信息，将北京市划分为一个个类似于正方形的小区间，统计历史数据半个小时在一个个小区间的车辆，并对实时数据统计每半个小时小区间的车辆，给出设计方案？ 大致这样
		考虑用什么数据库 哪些字段 需要考虑信息巨大
		
a   b     a   c
A 	10	  A	20:10        利用sql语句如何从表A（a,b）得到B（a,c）   （group_concat）  UDAF可以实现
A   20    B 10
B   10    C 30
C   30 
k-meams的原理
介绍下flume   source和sink的种类有哪些  监控一个文件用什么指令

宜信


 

  
