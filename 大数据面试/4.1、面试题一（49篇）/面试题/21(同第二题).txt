畅捷通（用友集团）
1.spark源码-DAG-Task--任务调度部分
2.submit相关配置：
submit --master	
--Executor cores	一般指定多大的资源？	一般一个Executor 1 core，1G，2--3个task	
继续问：写完spark程序如何知道多少个task？	（即资源如何调配的）

3.spark程序用什么语言写的？
4.算法和数据结构--要求，是基本的
5.机器学习的算法
6.机器学习项目用什么写的？
7.用Python写的什么？
8.redis  bit操作
9.redis用来做什么？  模型等，频繁调用的放在redis中，取其快
10.sample正负例样本表，标签是怎么打的？
11.数据来源是什么？
12.标签值是不是不多？（正负例样本表是标签+-1），他指的标签是维度
13.hbase   我说没用过
14.hive用哪个版本
15.shell熟不熟？文件查找用什么命令？文件内容过滤用什么？grep命名用过没？
16.flume 和 kafka什么区别？
17.spark streaming 例子。问维护做过没？说sparkStreaming的维护成本很高。	我告诉他是的，比如说可能会丢数据，wal会慢。这一块儿不是我维护。没细问。
18.hive窗口函数
19.写sql：1月100,2月200,3月100,4月200.统计如下效果：1月100,2月300,3月500,4月600.【就是每月统计一次前面所有的月的总额】	加个over，就可以orderby   与partitionby类似
20.机器学习各种算法都了解吗？接下来问的聚类算法，k-means
21.hive 2.0 lllip  tz 了解吗？新特性？
22.spark和mr性能是不是差别很多？
23.机器学习是不是不能用mr？
24.面试官补充：spark也支持小内存的。有个参数，每个阶段都可以。
25.再一次提起数据结构和算法
26.期望薪资