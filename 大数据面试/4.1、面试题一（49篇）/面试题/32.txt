今天收到一个offer,, 东软,,是外包的,,,   貌似是金融相关的大数据项目
 13K,,实习期内是也是13K.  有补充公积金. 有年终奖. 每年涨一次工资.

上海这边的大数据很少有笔试,,, 有笔试也是一些java的题目,今天第一天面试.

面试问题总结:
	1.阿里巴巴的电话面试问到了linux的详细启动过程.  当时没回答出来...
    		1.按下电源
		2.BIOS自检
		3.系统引导(lilo/grub)
		4.启动内核
		5.初始化系统

	2.问到了还使用过其他什么开源框架.
		我就把我知道的apache的开源框架扯了一遍
	3.问到了最擅长那种技术
		我就说我对hadoop生态系统的技术比较擅长,
		然后介绍了mapreduce的详细过程和hsfs的架构.
	4.问到了hive的优化
		因为hive底层是mapreduce,所以就把maprecue的优化介绍了一下.
		比如多个map任务会比较消耗系统的资源,那么,在执行操作前,
		应该预先把小文件合并为大文件.
		reducer的数量可以根据公式去配置(hadoop文档中推荐的)
			0.95*NUMBER_OF_NODES*mapred.tasktracker.reduce.tasks.maximum
			1.75*NUMBER_OF_NODES*mapred.tasktracker.reduce.tasks.maximum
			备注：NUMBER_OF_NODES是集群中的计算节点个数；
			在代码中可以通过:jobConf.setNumReduceTasks(int numOfreduceTasks);方法设置reducer的个数
		可以写一个UDF函数,并且在建hive表的时候指定好分区, 这样就提交了数据扫描的效率
		可以修改配置文件,配置在map端的合并为true
		
		
	5.问到了在实际开发的过程中遇到了什么问题.
		我回答了.hbase的开发的过程中运行很慢,有时候会宕机.
		然后通过查看日志和观察配置文件发现,hfile的内容过小, 到职hbase频繁的split. 可以修改hfile的大小来避免这种情况.
		然后把major compact也设置为手动,  
	6.然后问我major compack设置为手动会出现什么问题.....
		没有回答出来,,感觉实际开发中应该不会这样去处理吧....
	

	7.很多公司都会问zookeeper的二次开发.
	
	8.有些公司会问的非常详细,,,比如flume在实际项目里面的数据采集....
		当时老师讲的是通过java端有一个jar包里面有个类作为客户端,,,将数据发送到flume,,,,
		但是面试官说: 这样项目和flume的耦合就比较高,,,如果flume挂掉了,,,对项目有影响....
		实际开发的过程中,,是利用flume的命令去定时采集数据的.
		还问到了flume的实时采集数据和定时采集数据的方法,,,
		回答的不是太好,,,
	
	9.有公司问到了mongoDB和hbase的区别....
		不是太了解,,就把hbase的概念给描述了一下
	
	10.还有不少公司会问...
		你做大数据的工作,,感觉自己工作里面做的最好的是哪一块..
		我觉得这样的问题真心不好回答,,,这很明显是个陷阱.....一旦跳进去就等着被虐吧....
	
	11.有不少公司会问项目组有多少人,,,人员的分工是如何的,,,数据量,,,还有集群的配置....
	     这些东西一定要想清楚啊,,,问的概率太高了...
             我回答每天数据量100G人家觉得太少了..
	
		
		
		
		
		