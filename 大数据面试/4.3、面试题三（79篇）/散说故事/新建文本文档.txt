问答题：
1.50亿个url，，每个64b，也就是一共大约320G，两个320G的文件进行比较，找重复行，内存限制是4G，也就是说大约可以分80个分区，将a文件和b文件每行url进行hash之后，跟80取模，会将a和b文件各自分成80个小文件，然后将a文件的0号分区读入内存，然后b文件0号分区每次读取一行找与a文件0号分区中hash值相同的，然后再将url取出之后比较url是否相同，相同就放到结果文件中，循环往复上述过程。



Map端的Shuffle过程

1、数据分片 
2、运算结果写入缓存 
3、缓存达到阈值，溢写到磁盘文件 
溢写前会进行分区，分区内排序和合并（可选） 
4、归并成大文件 
每次溢写会生成一个溢写文件，这些溢写文件最终需要被归并成一个大文件。 
归并的意思：生成key和对应的value-list。 
文件归并时，如果溢写文件数量超过参数min.num.spills.for.combine的值（默认为3）时，可以再次进行合并

每个Map任务分配一个缓存
MapReduce默认100MB缓存
设置溢写比例0.8
分区默认采用哈希函数
排序是默认的操作
排序后可以合并（Combine）
合并不能改变最终结果
在Map任务全部结束之前进行归并
归并得到一个大的文件，放在本地磁盘
文件归并时，如果溢写文件数量大于预定值（默认是3）则可以再次启动Combiner，少于3不需要

Reduce端的Shuffle过程
1、领取数据 
2、归并数据 
3、数据输入给Reduce任务

Reduce任务通过RPC向JobTracker询问Map任务是否已经完成，若完成，则领取数据
Reduce领取数据先放入缓存，来自不同Map机器，先归并，再合并，写入磁盘 多个溢写文件归并成一个或多个大文件，文件中的键值对是排序的
当数据很少时，不需要溢写到磁盘，直接在缓存中归并，然后输出给Reduce





















